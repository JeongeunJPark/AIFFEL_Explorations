{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 06_작사가 인공지능 만들기       \n",
    "\n",
    "\n",
    "## 이 노드의 루브릭   \n",
    "\n",
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?     \n",
    "    -> \"텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?       \n",
    "    \n",
    "\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?     \n",
    "    -> \"특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?\"          \n",
    "    \n",
    "\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?     \n",
    "    -> \"텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 루브릭에 주의하며 작사가 인공지능을 만들어 보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 가져오기          \n",
    "\n",
    "- 데이터가 잘 준비되었음을 알 수 있다.\n",
    "\n",
    "![데이터 준비](./PostingPic/데이터준비.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 읽어오기    \n",
    "\n",
    "* 데이터를 raw_corpus에 담는다.(가사를 정제해서 텐서화 시킬 raw_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위치 :  /home/ssac23/SUBMIT_MISSION_GIT/ex6_Composer/lyrics/*\n",
      "데이터 크기 :  187088\n",
      "Examples :  ['', '', '[Spoken Intro:]']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_path = os.getenv('HOME')+'/SUBMIT_MISSION_GIT/ex6_Composer/lyrics/*'\n",
    "txt_list = glob.glob(txt_path)\n",
    "\n",
    "print(\"위치 : \" ,txt_path)\n",
    "\n",
    "raw_corpus =[]\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    \n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        \n",
    "        #리스트.extend(내용), 리스트 끝에 raw의 모든 항목을 넣는다.\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print(\"데이터 크기 : \", len(raw_corpus))\n",
    "print(\"Examples : \", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 번외(궁금해서 해봤다)  \n",
    "\n",
    "- 새로운 파이썬 문법.. raw_corpus.extend(raw)가 나와서 검색해봤더니, append와 비슷한 거라고 한다.   \n",
    "- 근데, 어떤 부분이 다른거지? 그걸 알기 위해 한 번 해봤더니...!\n",
    "\n",
    "![궁금해서 해봤더니](./PostingPic/append할때.png)   \n",
    "\n",
    "\n",
    "- 위에서 raw는 \n",
    "  1. lyrics 폴더의 모든 텍스트 리스트(txt_list)에서 가져온     \n",
    "  2. 하나의 텍스트 파일(txt_file)에서 읽어온 splitlines() 이다.    \n",
    "---\n",
    "- 얘를 append 하면 하나의 파일만 읽어오고,    \n",
    "- 얘를 extend 하면 그 폴더의 모든 파일의 데이터가 읽어와진다.    \n",
    "---\n",
    "__WHY?__\n",
    "> - append : object(그 해당 오브젝트)를 맨 뒤에 추가한다.    \n",
    "> - extend : iterable객체(리스트, 튜플, 딕셔너리)의 원소를 list에 appending 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 정제하기    \n",
    "\n",
    "* preprocess_sentence() 함수에서 나타난 다양한 스킬들을 통해 데이터를 정제한다.    \n",
    "* 단, 문장을 토큰화했을 때 토큰의 개수가 15개가 넘어가는 문장은 학습데이터에서 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 데이터 정제하기\n",
    "\n",
    "####  혹시 모를 특수문자, 대소문자, 문장부호를 정제하고, 소스 첫단과 끝단에 start와 end를 붙여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(\"([?.!,?,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub('[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정제 후 new_corpus의 길이 :  187088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<start> you ever want something <end>',\n",
       " '<start> that you know you shouldn t have <end>',\n",
       " '<start> the more you know you shouldn t have it , <end>',\n",
       " '<start> the more you want it <end>',\n",
       " '<start> and then one day you get it , <end>',\n",
       " '<start> it s so good too <end>',\n",
       " '<start> but it s just like my girl <end>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정제된 표현을 담을 new_corpus 배열을 선언한다.\n",
    "\n",
    "new_corpus = []\n",
    "\n",
    "for sentence in raw_corpus :\n",
    "    new_corpus.append(preprocess_sentence(sentence))\n",
    "    \n",
    "print(\"정제 후 new_corpus의 길이 : \", len(new_corpus))\n",
    "new_corpus[3:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정제한 문장을 토큰화하고, 단어 사전을 만들며, 데이터를 숫자로 변환하기 == \"토큰화하기\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    3    0 ...    0    0    0]\n",
      " [   2    3    0 ...    0    0    0]\n",
      " [   2 2706 2589 ...    0    0    0]\n",
      " ...\n",
      " [   2  130    5 ...    0    0    0]\n",
      " [   2   23   89 ...    0    0    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fb5f922e8d0>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    \n",
    "    #순서대로 전체 단어의 개수, 추가할 전처리 로직, out-of vocabulary(사전에 없는 단어를 무엇으로 대체할지)\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words =12000, filters='' , oov_token=\"<unk>\")\n",
    "    \n",
    "    #우리가 정제한 corpus를 토큰화하여 사전으로 변환\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    #입력 데이터의 시퀀스 길이를 맞추기 위해 padding 메소드 적용\n",
    "    #maxlen의 default 값은 None으로, corpus의 가장 긴 문장을 기준으로 시퀀스 길이를 맞춤\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    print(tensor, tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(new_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 첫단은 2(start)로, 뒤에는 '패딩' 이 들어간 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187088\n",
      "[[   2    3    0 ...    0    0    0]\n",
      " [   2    3    0 ...    0    0    0]\n",
      " [   2 2706 2589 ...    0    0    0]\n",
      " ...\n",
      " [   2  130    5 ...    0    0    0]\n",
      " [   2   23   89 ...    0    0    0]\n",
      " [   2    7   34 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(tensor))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화했을때, 너무 긴 문장은 작사하는데 맞지 않을 수 있다. 길이가 15가 넘어가는 데이터는 지우자!        \n",
    "\n",
    "- 위에서 변환된 텐서를 출력해보았을 때, 187088개의 데이터가 무사히 텐서로 변환되었지만     \n",
    "- 변환된 텐서의 끝에 공백이 0 이 들어가는 데이터가 너무 많아 문제인 것을 알 수 있다.     \n",
    "- 모델의 성능에 영향을 미칠 수 있으므로 공백기준 15개 미만의 단어만 tensor 안에 넣어주고,     \n",
    "- 텐서의 개수를 출력해보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    3    0 ...    0    0    0]\n",
      " [   2    3    0 ...    0    0    0]\n",
      " [   2 2569 2160 ...    0    0    0]\n",
      " ...\n",
      " [   2  677   30 ...  428    3    0]\n",
      " [   2    4  124 ...   10    7    3]\n",
      " [   2    7   37 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fb5f6ff2150>\n",
      "142296\n"
     ]
    }
   ],
   "source": [
    "temp_corpus = []\n",
    "\n",
    "#혹시 몰라서 <start>, <end>를 빼서 계산했다.\n",
    "for sentences in new_corpus:\n",
    "    if len(sentences.split(' ')) < 13:\n",
    "        temp_corpus.append(sentences)\n",
    "        \n",
    "tensor, tokenizer = tokenize(temp_corpus)\n",
    "print(len(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 142296개의 텐서가 생성되었다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  평가 데이터셋 분리          \n",
    "\n",
    "- sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 한다.     \n",
    "- 단어장의 크기는 12,000개, 총 데이터의 20%는 평가 데이터셋이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source_train :  (113836, 11)\n",
      "Target_train :  (113836, 11)\n"
     ]
    }
   ],
   "source": [
    "#사용할 라이브러리 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#소스데이터와 타겟데이터 \n",
    "#텐서의 끝 end 데이터를 잘라 source_data로,\n",
    "#텐서의 앞 start 데이터를 잘라 target_data로 변환\n",
    "sor_data = tensor[:, :-1]\n",
    "tar_data = tensor[:, 1:]\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(sor_data, tar_data, test_size=0.2, random_state=28)\n",
    "\n",
    "#노드에서 명시한 데이터셋보다는 조금 다르긴 한데...!\n",
    "print(\"Source_train : \" , enc_train.shape)\n",
    "print(\"Target_train : \", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 객체 생성하기     \n",
    "\n",
    "- 텐서를 dataset으로 변환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size :  12001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 11), (256, 11)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buffer_size = len(enc_train)\n",
    "Batch_size = 256\n",
    "\n",
    "steps_per_epoch = len(enc_train)//Batch_size\n",
    "\n",
    "#토크나이저가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 <pad> 까지 7,001개\n",
    "Vocab_size = tokenizer.num_words+1\n",
    "print(\"Vocab size : \" , Vocab_size)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(Buffer_size)\n",
    "dataset = dataset.batch(Batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 인공지능 만들기        \n",
    "\n",
    "- 모델의 Embedding Size와 Hidden Size를 조절하여 __10Epoch 안에 val_loss 값을 2.2 수준으로 줄이는 모델__ 을 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow! 모델세팅 완료\n"
     ]
    }
   ],
   "source": [
    "#일단 첫번째 시도에서는 embedding size와 hidden size를 기본(노드 실습 때의 설정)으로 둔 뒤, val_loss가 얼마나 나오는지 본다.\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words +1, embedding_size, hidden_size)\n",
    "print(\"wow! 모델세팅 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 주어진 요건에 맞게 첫 모델을 compile 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 11, 12001), dtype=float32, numpy=\n",
       "array([[[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-6.19117345e-04,  4.19090138e-05,  2.99521838e-04, ...,\n",
       "         -1.19447395e-04, -4.06953885e-04, -5.45289622e-05],\n",
       "        [-8.20669753e-04,  1.54263558e-04,  4.75376757e-04, ...,\n",
       "          2.63935617e-05, -4.47625906e-04, -1.16864736e-04],\n",
       "        ...,\n",
       "        [-1.02281990e-03,  6.36482611e-04,  1.39067555e-03, ...,\n",
       "          1.86405994e-03,  6.56221819e-04,  8.27232798e-05],\n",
       "        [-1.01015985e-03,  6.32838812e-04,  1.55789941e-03, ...,\n",
       "          2.10645865e-03,  8.47418385e-04,  1.58480529e-04],\n",
       "        [-1.00023532e-03,  6.16948877e-04,  1.72287656e-03, ...,\n",
       "          2.31856480e-03,  1.02033431e-03,  2.27079989e-04]],\n",
       "\n",
       "       [[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-7.21390243e-04, -3.11465883e-05,  3.70515452e-04, ...,\n",
       "         -3.69734567e-04, -9.01041640e-05, -1.62854180e-04],\n",
       "        [-1.00524351e-03, -1.53382483e-04,  5.70726057e-04, ...,\n",
       "         -3.69715650e-04, -9.73302595e-05, -5.88971714e-04],\n",
       "        ...,\n",
       "        [-8.87143950e-04,  3.11800162e-04,  1.35135779e-03, ...,\n",
       "         -4.86485485e-04,  2.15502267e-04, -4.26434592e-04],\n",
       "        [-9.63067345e-04,  4.64338838e-04,  1.52542430e-03, ...,\n",
       "         -8.79951767e-05,  3.73103685e-04, -5.37416781e-04],\n",
       "        [-1.01614196e-03,  5.98837738e-04,  1.66227494e-03, ...,\n",
       "          3.51355848e-04,  5.67935989e-04, -6.06964226e-04]],\n",
       "\n",
       "       [[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-6.59008045e-04, -2.38287161e-04,  9.65120926e-05, ...,\n",
       "          1.22337777e-04, -2.68398493e-04, -1.22361875e-04],\n",
       "        [-7.31646607e-04, -1.29239183e-04, -5.16034415e-05, ...,\n",
       "         -4.32515626e-05, -4.72188876e-05, -1.47255399e-04],\n",
       "        ...,\n",
       "        [-6.06041693e-04, -2.84392911e-04,  5.20648726e-04, ...,\n",
       "          4.58117633e-04,  2.46803917e-04, -8.86987429e-04],\n",
       "        [-5.85747126e-04, -2.47986554e-05,  6.45772030e-04, ...,\n",
       "          8.27509502e-04,  3.87744280e-04, -8.35379935e-04],\n",
       "        [-5.77501953e-04,  2.04305717e-04,  7.93839514e-04, ...,\n",
       "          1.20193558e-03,  5.31136233e-04, -7.54552952e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-3.54779128e-04, -1.57911607e-04, -1.32091052e-04, ...,\n",
       "          1.74043569e-04, -6.21224928e-04, -1.62452008e-04],\n",
       "        [-5.00372262e-04,  5.81661625e-05, -1.64122233e-04, ...,\n",
       "          1.39686599e-04, -1.23364269e-03,  5.75333106e-05],\n",
       "        ...,\n",
       "        [-1.64339799e-05, -8.17720866e-05, -1.26613202e-04, ...,\n",
       "         -1.12742091e-04, -1.50887959e-03,  4.00080811e-04],\n",
       "        [-1.99348346e-04, -1.41225551e-04,  1.75571680e-04, ...,\n",
       "         -1.94418026e-04, -1.62297068e-03,  1.72283399e-04],\n",
       "        [-3.46889748e-04, -8.84457313e-06,  4.32396249e-04, ...,\n",
       "         -8.66717382e-05, -1.48117135e-03, -1.16033283e-04]],\n",
       "\n",
       "       [[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-4.83484968e-04, -2.11357430e-04,  2.79800035e-04, ...,\n",
       "          2.98850093e-04, -3.75937991e-04,  1.11281704e-04],\n",
       "        [-5.12519735e-04, -6.94300805e-04,  2.81601882e-04, ...,\n",
       "          3.49664333e-04, -3.39938240e-04,  3.81494989e-04],\n",
       "        ...,\n",
       "        [-1.22590456e-04, -8.80062347e-04,  6.78762386e-04, ...,\n",
       "         -4.33396199e-04, -2.94575602e-05,  1.26951738e-04],\n",
       "        [-9.84312428e-05, -5.16231230e-04,  8.08873388e-04, ...,\n",
       "         -3.22436652e-04, -1.81696858e-04,  4.91453065e-05],\n",
       "        [-9.41042526e-05, -8.27554177e-05,  9.04139015e-04, ...,\n",
       "         -7.15987480e-05, -9.83001519e-05, -3.18140446e-05]],\n",
       "\n",
       "       [[-3.22062901e-04,  4.12608206e-05,  9.85148799e-05, ...,\n",
       "         -5.86009155e-05, -1.44538324e-04, -2.25622662e-05],\n",
       "        [-6.19117345e-04,  4.19090138e-05,  2.99521838e-04, ...,\n",
       "         -1.19447395e-04, -4.06953885e-04, -5.45289622e-05],\n",
       "        [-8.20669753e-04,  1.54263558e-04,  4.75376757e-04, ...,\n",
       "          2.63935617e-05, -4.47625906e-04, -1.16864736e-04],\n",
       "        ...,\n",
       "        [-1.02281990e-03,  6.36482611e-04,  1.39067555e-03, ...,\n",
       "          1.86405994e-03,  6.56221819e-04,  8.27232798e-05],\n",
       "        [-1.01015985e-03,  6.32838812e-04,  1.55789941e-03, ...,\n",
       "          2.10645865e-03,  8.47418385e-04,  1.58480529e-04],\n",
       "        [-1.00023532e-03,  6.16948877e-04,  1.72287656e-03, ...,\n",
       "          2.31856480e-03,  1.02033431e-03,  2.27079989e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 전 샘플!\n",
    "for enc_train, dec_train in dataset.take(1):\n",
    "    break\n",
    "    \n",
    "model(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 궁금한 점 : model.summary() 가 안된다   \n",
    "\n",
    "- if(68번 코드를 실행하지 않으면) : model.summary() 가 오류난다.\n",
    "- 왜일까?\n",
    "- 한번 찾아봐야겠다.\n",
    "\n",
    "![서머리오류메세지](./PostingPic/6_서머리오류.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능 훈련, 10epoch로 val_loss 2.2 이하로 만들기.     \n",
    "\n",
    "- 도전!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "444/444 [==============================] - 52s 116ms/step - loss: 3.7273\n",
      "Epoch 2/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 3.2307\n",
      "Epoch 3/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 3.0553\n",
      "Epoch 4/10\n",
      "444/444 [==============================] - 52s 118ms/step - loss: 2.9095\n",
      "Epoch 5/10\n",
      "444/444 [==============================] - 53s 120ms/step - loss: 2.7847\n",
      "Epoch 6/10\n",
      "444/444 [==============================] - 53s 119ms/step - loss: 2.6730\n",
      "Epoch 7/10\n",
      "444/444 [==============================] - 53s 120ms/step - loss: 2.5697\n",
      "Epoch 8/10\n",
      "444/444 [==============================] - 53s 120ms/step - loss: 2.4731\n",
      "Epoch 9/10\n",
      "444/444 [==============================] - 53s 119ms/step - loss: 2.3814\n",
      "Epoch 10/10\n",
      "444/444 [==============================] - 53s 118ms/step - loss: 2.2943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5f7101dd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 첫 시도에서 나쁘지 않게 나왔다. 하지만 저 과정에서 느꼈을 감정을 서술하시오(5점)    \n",
    "\n",
    "![10번째 epoch](./PostingPic/6_10번째에폭.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 무엇을 고쳐봐야 더 괜찮게 나올까?       \n",
    "- 임베딩 데이터는 단어가 추상적으로 표현되는 크기이며, 히든 사이즈는 얼마나 x인풋(히든 레이어에서)을 줄 것인지를 의미한다.     \n",
    "- 임베딩 데이터의 크기를 더 늘려보자.(단어의 표현 강도를 최대 5점 만점에서 10점 만점으로 늘리는 것처럼)  \n",
    "\n",
    "> 기존의 embedding_size = 256, hidden_size = 1024에서       \n",
    "> embedding_size = 512로 바꿔본다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow! 모델세팅 완료\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 1024\n",
    "model2 = TextGenerator(tokenizer.num_words +1, embedding_size, hidden_size)\n",
    "print(\"wow! 모델세팅 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "model2.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 11, 12001), dtype=float32, numpy=\n",
       "array([[[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [ 5.24531897e-05,  1.21936122e-04,  3.16820806e-04, ...,\n",
       "         -1.25118924e-04,  5.19435620e-04, -1.06318221e-04],\n",
       "        [ 7.25991151e-04,  7.85286102e-05,  2.61733163e-04, ...,\n",
       "         -3.97211898e-06,  6.36752869e-04, -3.72508162e-04],\n",
       "        ...,\n",
       "        [ 7.58138834e-04,  8.83960456e-05,  1.63524121e-03, ...,\n",
       "          2.49146658e-04,  1.44285278e-03, -1.91889441e-04],\n",
       "        [ 8.93491495e-04, -6.30720751e-05,  2.17490876e-03, ...,\n",
       "          1.21575154e-04,  1.42013980e-03, -1.49681102e-04],\n",
       "        [ 9.55307041e-04,  4.30408458e-04,  2.04905705e-03, ...,\n",
       "          2.98852829e-04,  1.37665437e-03, -2.85403017e-04]],\n",
       "\n",
       "       [[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [-6.06535759e-04,  2.41541420e-05, -4.05263301e-04, ...,\n",
       "         -1.21861867e-05,  5.96456171e-04,  4.71483712e-04],\n",
       "        [-7.47065118e-04, -1.30583649e-04, -2.93020334e-04, ...,\n",
       "         -1.70368003e-04,  4.88827704e-04,  1.20016525e-03],\n",
       "        ...,\n",
       "        [-1.01037789e-03, -8.07665463e-04, -8.20023270e-05, ...,\n",
       "          3.20630468e-04, -4.32291592e-04,  7.19850286e-05],\n",
       "        [-1.03300018e-03, -1.01323461e-03,  2.18535788e-04, ...,\n",
       "          2.38858993e-04, -3.69224814e-04,  2.42925773e-04],\n",
       "        [-1.03275129e-03, -1.07774429e-03, -1.01521960e-04, ...,\n",
       "         -2.72533653e-04, -3.56392498e-04,  5.38621040e-04]],\n",
       "\n",
       "       [[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [-1.48992607e-04, -4.56637354e-04,  5.14747035e-06, ...,\n",
       "         -1.25363349e-05,  2.17883338e-04, -3.24453140e-04],\n",
       "        [-2.72020319e-04, -8.19224806e-04,  8.69733776e-05, ...,\n",
       "          2.29917321e-04,  4.79847164e-04, -6.11848489e-04],\n",
       "        ...,\n",
       "        [-1.52412438e-04, -2.25004347e-04, -1.17220388e-05, ...,\n",
       "          8.78435822e-05, -1.28579661e-04, -7.19554082e-04],\n",
       "        [ 1.06595886e-04,  2.64173403e-04,  4.55934525e-04, ...,\n",
       "         -8.18791159e-05,  1.94773151e-04, -6.79998891e-04],\n",
       "        [-1.49373227e-04,  9.13442695e-04,  5.15417545e-04, ...,\n",
       "          2.18073299e-04,  2.90178985e-04, -1.25993814e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [-5.03301970e-04, -4.38221410e-04,  1.68424973e-04, ...,\n",
       "         -2.43740316e-04,  3.76951764e-04, -2.84442009e-04],\n",
       "        [-7.28213228e-04, -4.84930730e-04,  1.70551197e-04, ...,\n",
       "         -5.04964672e-04,  1.36953604e-04, -5.84748690e-04],\n",
       "        ...,\n",
       "        [-1.68515151e-04, -1.57045477e-04,  1.73183670e-03, ...,\n",
       "         -7.83252995e-04, -2.34876807e-05, -9.43129649e-04],\n",
       "        [-5.69322321e-04,  1.73382155e-04,  1.74391281e-03, ...,\n",
       "         -9.73164453e-04, -2.71671423e-04, -7.06555380e-04],\n",
       "        [-1.05417194e-03,  4.72843763e-04,  1.82517653e-03, ...,\n",
       "         -1.39734615e-03, -6.22564810e-04, -5.88146679e-04]],\n",
       "\n",
       "       [[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [-5.98023296e-04, -2.60194269e-04, -3.36523546e-04, ...,\n",
       "         -3.51604074e-04, -1.32526518e-04,  2.76940613e-04],\n",
       "        [-3.99684330e-04, -1.91940737e-04, -2.54440636e-07, ...,\n",
       "         -4.73986816e-04, -8.29395285e-05,  3.38460959e-04],\n",
       "        ...,\n",
       "        [ 5.39981818e-04, -5.93236415e-04,  1.27979158e-03, ...,\n",
       "         -1.36080047e-03, -1.06838543e-03,  5.57681604e-04],\n",
       "        [ 6.88102213e-04, -4.26583516e-04,  1.46601652e-03, ...,\n",
       "         -1.54331268e-03, -1.09912094e-03,  1.70176165e-04],\n",
       "        [ 8.79925385e-04, -3.71695438e-04,  1.65814429e-03, ...,\n",
       "         -1.41114404e-03, -1.13137322e-03,  1.34381378e-04]],\n",
       "\n",
       "       [[-2.13754392e-04, -3.39395447e-05, -9.05460474e-05, ...,\n",
       "         -8.88166396e-05,  2.15033055e-04, -3.14734716e-05],\n",
       "        [-7.25074904e-04,  3.13124823e-04, -2.90562893e-04, ...,\n",
       "          3.79884004e-04,  2.39550413e-04,  4.72468644e-04],\n",
       "        [-1.30217406e-03,  5.54931292e-04, -2.88703828e-04, ...,\n",
       "          2.69623037e-04, -5.44169088e-05,  6.28668000e-04],\n",
       "        ...,\n",
       "        [-3.42378695e-03,  2.50693155e-03,  1.76968833e-03, ...,\n",
       "         -2.91112112e-03, -2.48845271e-03,  7.04346865e-04],\n",
       "        [-3.53333843e-03,  2.85990606e-03,  2.16084789e-03, ...,\n",
       "         -3.36250453e-03, -2.74514384e-03,  7.99867383e-04],\n",
       "        [-3.59774823e-03,  3.19113419e-03,  2.52019172e-03, ...,\n",
       "         -3.76097695e-03, -2.96169217e-03,  9.10793955e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for enc_train, dec_train in dataset.take(1):\n",
    "    break\n",
    "    \n",
    "model2(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                multiple                  6295552   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 33,133,793\n",
      "Trainable params: 33,133,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "444/444 [==============================] - 49s 110ms/step - loss: 2.2115\n",
      "Epoch 2/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 2.1332\n",
      "Epoch 3/10\n",
      "444/444 [==============================] - 51s 115ms/step - loss: 2.0591\n",
      "Epoch 4/10\n",
      "444/444 [==============================] - 52s 116ms/step - loss: 1.9877\n",
      "Epoch 5/10\n",
      "444/444 [==============================] - 52s 116ms/step - loss: 1.9207\n",
      "Epoch 6/10\n",
      "444/444 [==============================] - 52s 116ms/step - loss: 1.8557\n",
      "Epoch 7/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 1.7945\n",
      "Epoch 8/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 1.7352\n",
      "Epoch 9/10\n",
      "444/444 [==============================] - 52s 116ms/step - loss: 1.6783\n",
      "Epoch 10/10\n",
      "444/444 [==============================] - 52s 117ms/step - loss: 1.6251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5f68eafd0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2차 시도\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과가 나왔다!!!! 1.62의 loss이다.  \n",
    "\n",
    "#### 이제 작사를 좀 시켜보자. 제시어는 노드에 있던 'i love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    \n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환한다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # 입력받은 문장의 텐서를 입력하고, \n",
    "        predict = model(test_tensor)   \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]  \n",
    "\n",
    "        # 새로 예측한 단어를 입력 단어 뒤에 붙여준다(RNN 순환)\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  \n",
    "        # while 루프를 또 돌면서 다음 단어를 예측하게 한다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "   \n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 사람이 이해 가능한 문자로 변환한다.\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you more than i did <end> '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love aieeah aieeah shared shared switches clumsy clumsy maxwell brag brag brag brag compete compete carousel carousel carousel '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model2, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 혹시 몰라서 val_loss가 2.2에 근접했던 model1과, 목표달성에 성공한 model2를 동시에 돌렸더니     \n",
    "* 결과가 이렇게 나왔다.      \n",
    "\n",
    "### 왜 이러는걸까?     \n",
    "\n",
    "- ~model2는 사랑에 실패한 게 분명하다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> today lag murderers murderers ktown nobody nobody ktown tragedies tragedies tragedies tragedies tragedies chased fundamental fundamental fundamental fundamental diggin '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model2, tokenizer, init_sentence=\"<start> today \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> today , today , it s too late <end> '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> today \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 작사는 model 니가 해, model2는 하기 싫은가보다\n",
    "\n",
    "- 둘 사이에 달라진거라고는 임베딩 사이즈 뿐인데, 뭔가 이상하다.    \n",
    "- 검색과 하이퍼파라미터 변경을 통해, 같은 조건(val_loss 2.2 이하) 잘 작사하는 모델으로 보완해보겠다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
